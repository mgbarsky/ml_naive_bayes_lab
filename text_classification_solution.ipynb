{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Naive Bayes: Text Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab is to build a model using Naive Bayes to classify movie reviews into positive or negative, and then test the classifier on new movie reviews.\n",
    "The dataset can be downloaded from read me: movies_reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/elaine/Desktop/ML2020labs/movies_reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'neg', 'pos', 'new_review']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1005)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_files = []\n",
    "pos_path_files = data_dir +\"/pos/\"\n",
    "for path in os.listdir(pos_path_files):\n",
    "    if '.txt' in path:\n",
    "        pos_files.append(os.path.join(pos_path_files, path))\n",
    "        \n",
    "neg_files = []\n",
    "neg_path_files = data_dir +\"/neg/\"\n",
    "for path in os.listdir(neg_path_files):\n",
    "    if '.txt' in path:\n",
    "        neg_files.append(os.path.join(neg_path_files, path))\n",
    "        \n",
    "len(neg_files), len(pos_files) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I made the file names into two list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review = ['' for i in range(1000)]\n",
    "neg_review = ['' for i in range(1000)]\n",
    "for i in range(1000):    \n",
    "    file = pos_files[i]\n",
    "    f = open(file, \"r\")\n",
    "    pos_review[i] = f.read()\n",
    "    f.close()\n",
    "    \n",
    "for i in range(1000):   \n",
    "    file = neg_files[i]\n",
    "    f = open(file, \"r\")\n",
    "    neg_review[i] = f.read()\n",
    "    f.close()\n",
    "    \n",
    "# print(pos_review[0])\n",
    "# print(neg_review[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i have two lists, X_pos and X_neg.\n",
    "Both of them are storing the texts.\n",
    "Each element in the list is the content of a file. \n",
    "And now i want to preprocess my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the data since CountVectorizer don't remove all the characters we don't want \n",
    "for i in range(1000):    \n",
    "    review = pos_review[i] \n",
    "    review = review.lower()\n",
    "    review = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", '', review)\n",
    "    review = re.sub(r'[^\\w\\s]', '', review) \n",
    "    review = review.strip()\n",
    "    review = review.replace(\"_\", \"\")\n",
    "    pos_review[i] = review\n",
    "    \n",
    "for i in range(1000):   \n",
    "    review = neg_review[i] \n",
    "    review = review.lower()\n",
    "    review = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", ' ', review)\n",
    "    review = re.sub(r'[^\\w\\s]', '', review) \n",
    "    review = review.strip()\n",
    "    review = review.replace(\"_\", \"\")\n",
    "\n",
    "    neg_review[i] = review\n",
    "    \n",
    "# this also works\n",
    "# review = neg_review[i] \n",
    "# review = re.sub(r\"\"\"\\w*\\d\\w*\"\"\", '', review)\n",
    "# punc_lower = re.sub('[%s]' % re.escape(string.punctuation), '', review.lower())\n",
    "# review = neg_review[i] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dataset into Test and Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = ['pos']*800 + ['neg']*800\n",
    "Y_test = ['pos']*200 + ['neg']*200\n",
    "X_train = pos_review[:800] + neg_review[:800]\n",
    "X_test = pos_review[800:] + neg_review[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 43021)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Cvectorizer = CountVectorizer(stop_words='english')\n",
    "#Initializing CountVectorizer from sklearn\n",
    "X_train = Cvectorizer.fit_transform(X_train) \n",
    "X_test = Cvectorizer.transform(X_test) \n",
    "\n",
    "#Print the dimensions of the processed data for checking of the code run successfully\n",
    "print(X_train.toarray().shape)\n",
    "# print(Cvectorizer.get_feature_names())\n",
    "# X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used CountVectorizer. CountVectorizer.fit_transform(X_train) is to transform the the X_train data from a list of texts to a matrix that each row is a vector that indicate the occurance of words.\n",
    "For example, if i have the raw texts like:\n",
    "['i like apple', 'you like banana', 'he likes apple']\n",
    "then after the transformation, the CountVectorizer gives this:\n",
    "[[1,1,1,0,0,0]\n",
    "[0,1,0,1,1,0]\n",
    "[0,1,1,0,0,1]]\n",
    "where CountVectorizer.get_feature_names() is\n",
    "['i','like','apple','you','banana','he']\n",
    "It can also preprocess data like put the data into lower case, elimites the punctuations, empty spaces...\n",
    "Also, the CountVectorizer excludes the stopwords. In this lab, i choose 'english'. Cvectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the both of the models that i think can be used for text classification.\n",
    "The first one is CategoricalNB and the other one is MultinomialNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for CategoricalNB 0.976875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "# Y_train = Y_train.toarray()\n",
    "clf1 = CategoricalNB()\n",
    "X_train = X_train.toarray()\n",
    "clf1.fit(X_train, Y_train)\n",
    "Y_predict = clf1.predict(X_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy for CategoricalNB\", metrics.accuracy_score(Y_train, Y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for MultinomialNB 0.981875\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB().fit(X_train, Y_train)\n",
    "Y_predict = clf2.predict(X_train)\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy for MultinomialNB\", metrics.accuracy_score(Y_train, Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the models are doing very well in terms of accuracy for the training data. So i used both in the testing part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_test.toarray()\n",
    "# prediction_test1 = clf1.predict(X_test[0])\n",
    "# score1 = metrics.accuracy_score(Y_test, prediction_test1)\n",
    "# print('Total accuracy classification score with CategoricalNB: {}'.format(score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "however, i found out that this model (categoricalNB)doesn't work in this situation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy classification score with MultinomialNB: 0.8275\n"
     ]
    }
   ],
   "source": [
    "prediction_test2 = clf2.predict(X_test)\n",
    "score2 = metrics.accuracy_score(Y_test, prediction_test2)\n",
    "print('Total accuracy classification score with MultinomialNB: {}'.format(score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added 5 new reviews about one of my favorite movie, Flipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review3.txt\n",
      "review2.txt\n",
      "review1.txt\n",
      "review5.txt\n",
      "review4.txt\n"
     ]
    }
   ],
   "source": [
    "new_files = []\n",
    "new_path_files = data_dir +\"/new_review/\"\n",
    "for path in os.listdir(new_path_files):\n",
    "    if '.txt' in path:\n",
    "        print(path)\n",
    "        new_files.append(os.path.join(new_path_files, path))\n",
    "        \n",
    "new_review = ['' for i in range(5)]\n",
    "for i in range(5):    \n",
    "    file = new_files[i]\n",
    "    f = open(file, \"r\")\n",
    "    new_review[i] = f.read()\n",
    "    f.close()\n",
    "    \n",
    "for i in range(5):    \n",
    "    review = new_review[i] \n",
    "    review = review.lower()\n",
    "    review = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", '', review)\n",
    "    review = re.sub(r'[^\\w\\s]', '', review) \n",
    "    review = review.strip()\n",
    "    review = review.replace(\"_\", \"\")\n",
    "    new_review[i] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy classification score with MultinomialNB: 1.0\n",
      "['pos' 'pos' 'pos' 'neg' 'pos']\n",
      "['pos', 'pos', 'pos', 'neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "X_new = Cvectorizer.transform(new_review) \n",
    "prediction_new = clf2.predict(X_new)\n",
    "Y_new = ['pos','pos','pos','neg','pos']\n",
    "score3 = metrics.accuracy_score(Y_new, prediction_new)\n",
    "print('Total accuracy classification score with MultinomialNB: {}'.format(score3))\n",
    "print(prediction_new)\n",
    "print(Y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the reviews are classified correctly!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
